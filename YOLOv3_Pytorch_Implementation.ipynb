{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv3 Pytorch Implementation",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "3KSNfO0V_G3b",
        "colab_type": "code",
        "outputId": "225a9489-ed5c-4c65-d98f-7d4ecfc4c6ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Installing PyTorch \n",
        "!pip install openc\n",
        "#!pip install torch==0.4\n",
        "!wget https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/util.py\n",
        "!wget https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/darknet.py\n",
        "!wget https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/pallete\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==0.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
            "\u001b[K    100% |████████████████████████████████| 484.0MB 32kB/s \n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.46 has requirement numpy>=1.15, but you'll have numpy 1.14.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mfastai 1.0.46 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch\n",
            "  Found existing installation: torch 1.0.1.post2\n",
            "    Uninstalling torch-1.0.1.post2:\n",
            "      Successfully uninstalled torch-1.0.1.post2\n",
            "Successfully installed torch-0.4.0\n",
            "--2019-03-02 20:36:05--  https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/util.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7432 (7.3K) [text/plain]\n",
            "Saving to: ‘util.py’\n",
            "\n",
            "util.py             100%[===================>]   7.26K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-02 20:36:05 (114 MB/s) - ‘util.py’ saved [7432/7432]\n",
            "\n",
            "--2019-03-02 20:36:07--  https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/darknet.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9451 (9.2K) [text/plain]\n",
            "Saving to: ‘darknet.py’\n",
            "\n",
            "darknet.py          100%[===================>]   9.23K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-02 20:36:07 (134 MB/s) - ‘darknet.py’ saved [9451/9451]\n",
            "\n",
            "--2019-03-02 20:36:08--  https://raw.githubusercontent.com/AvivSham/YOLO_V3_from_scratch_colab/master/pallete\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 908 [application/octet-stream]\n",
            "Saving to: ‘pallete’\n",
            "\n",
            "pallete             100%[===================>]     908  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-02 20:36:09 (171 MB/s) - ‘pallete’ saved [908/908]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ew-bfiHu_Msb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63e68eed-04e2-4453-c85e-e6b97a5ed8b5"
      },
      "cell_type": "code",
      "source": [
        "#@title Import dependencies\n",
        "from __future__ import division\n",
        "import time\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import cv2 \n",
        "from util import *\n",
        "import argparse\n",
        "import os \n",
        "import os.path as osp\n",
        "from darknet import *\n",
        "import pickle as pkl\n",
        "import pandas as pd\n",
        "import random\n",
        "import csv\n",
        "cv2.__version__"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "3mT1ARDb_QE_",
        "colab_type": "code",
        "outputId": "fa63c650-02d7-4b16-d40a-07a51d07efab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Get weights and graph file for the model\n",
        "\n",
        "#Get weights file for the model\n",
        "!wget https://pjreddie.com/media/files/yolov3.weights\n",
        "# Get YOLO graph file\n",
        "!wget https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-02 20:36:46--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.3.39\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.3.39|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M  22.6MB/s    in 11s     \n",
            "\n",
            "2019-03-02 20:36:58 (21.1 MB/s) - ‘yolov3.weights’ saved [248007048/248007048]\n",
            "\n",
            "--2019-03-02 20:36:59--  https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8342 (8.1K) [text/plain]\n",
            "Saving to: ‘yolov3.cfg’\n",
            "\n",
            "yolov3.cfg          100%[===================>]   8.15K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-02 20:36:59 (77.7 MB/s) - ‘yolov3.cfg’ saved [8342/8342]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PZ3erh_m_UdC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Making directories for test photos\n",
        "!mkdir Images\n",
        "!mkdir Images_Detection\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e5j0UZsZ_Ztd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Changing working directory\n",
        "os.chdir(os.getcwd()+'/'+'Images')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TmJ7p9QL_diV",
        "colab_type": "code",
        "outputId": "75f261e4-1a81-4f9e-e055-d5fa294492a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Test\n",
        "os.getcwd()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Images'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "XhenW6Lm_gj1",
        "colab_type": "code",
        "outputId": "b05fa09a-b62a-4984-ccd8-82b008e6e4d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1941
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Get test images\n",
        "!wget https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/giraffe.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/messi.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img1.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img2.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img3.jpg\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img4.jpg\n",
        "!wget https://github.com/gagandeepsinghkhanuja/DeepLearningforNaturalDisasters/tree/master/Dataset/1.jpg \n",
        "!wget https://github.com/gagandeepsinghkhanuja/DeepLearningforNaturalDisasters/tree/master/Video-Dataset/Video1.mp4"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-02 21:02:50--  https://github.com/ayooshkathuria/pytorch-yolo-v3/raw/master/dog-cycle-car.png\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png [following]\n",
            "--2019-03-02 21:02:51--  https://raw.githubusercontent.com/ayooshkathuria/pytorch-yolo-v3/master/dog-cycle-car.png\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 347445 (339K) [image/png]\n",
            "Saving to: ‘dog-cycle-car.png’\n",
            "\n",
            "dog-cycle-car.png   100%[===================>] 339.30K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-03-02 21:02:51 (6.78 MB/s) - ‘dog-cycle-car.png’ saved [347445/347445]\n",
            "\n",
            "--2019-03-02 21:02:53--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/giraffe.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 382965 (374K) [image/jpeg]\n",
            "Saving to: ‘giraffe.jpg’\n",
            "\n",
            "giraffe.jpg         100%[===================>] 373.99K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2019-03-02 21:02:54 (7.34 MB/s) - ‘giraffe.jpg’ saved [382965/382965]\n",
            "\n",
            "--2019-03-02 21:02:55--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/messi.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 126867 (124K) [image/jpeg]\n",
            "Saving to: ‘messi.jpg’\n",
            "\n",
            "messi.jpg           100%[===================>] 123.89K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-03-02 21:02:56 (3.30 MB/s) - ‘messi.jpg’ saved [126867/126867]\n",
            "\n",
            "--2019-03-02 21:02:57--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img1.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 78771 (77K) [image/jpeg]\n",
            "Saving to: ‘img1.jpg’\n",
            "\n",
            "img1.jpg            100%[===================>]  76.92K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-02 21:02:57 (3.03 MB/s) - ‘img1.jpg’ saved [78771/78771]\n",
            "\n",
            "--2019-03-02 21:02:59--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img2.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 113300 (111K) [image/jpeg]\n",
            "Saving to: ‘img2.jpg’\n",
            "\n",
            "img2.jpg            100%[===================>] 110.64K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-03-02 21:02:59 (2.87 MB/s) - ‘img2.jpg’ saved [113300/113300]\n",
            "\n",
            "--2019-03-02 21:03:01--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img3.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102770 (100K) [image/jpeg]\n",
            "Saving to: ‘img3.jpg’\n",
            "\n",
            "img3.jpg            100%[===================>] 100.36K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2019-03-02 21:03:02 (2.69 MB/s) - ‘img3.jpg’ saved [102770/102770]\n",
            "\n",
            "--2019-03-02 21:03:04--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/imgs/img4.jpg\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84988 (83K) [image/jpeg]\n",
            "Saving to: ‘img4.jpg’\n",
            "\n",
            "img4.jpg            100%[===================>]  83.00K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2019-03-02 21:03:04 (3.30 MB/s) - ‘img4.jpg’ saved [84988/84988]\n",
            "\n",
            "--2019-03-02 21:03:07--  https://github.com/gagandeepsinghkhanuja/DeepLearningforNaturalDisasters/tree/master/Dataset/1.jpg\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/gagandeepsinghkhanuja/DeepLearningforNaturalDisasters/blob/master/Dataset/1.jpg [following]\n",
            "--2019-03-02 21:03:08--  https://github.com/gagandeepsinghkhanuja/DeepLearningforNaturalDisasters/blob/master/Dataset/1.jpg\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘1.jpg’\n",
            "\n",
            "1.jpg                   [  <=>               ]  50.89K   141KB/s    in 0.4s    \n",
            "\n",
            "2019-03-02 21:03:09 (141 KB/s) - ‘1.jpg’ saved [52112]\n",
            "\n",
            "--2019-03-02 21:03:11--  https://github.com/gagandeepsinghkhanuja/DeepLearningforNaturalDisasters/tree/master/Video-Dataset/Video1.mp4\n",
            "Resolving github.com (github.com)... 192.30.253.112, 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://github.com/gagandeepsinghkhanuja/DeepLearningforNaturalDisasters/blob/master/Video-Dataset/Video1.mp4 [following]\n",
            "--2019-03-02 21:03:11--  https://github.com/gagandeepsinghkhanuja/DeepLearningforNaturalDisasters/blob/master/Video-Dataset/Video1.mp4\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘Video1.mp4’\n",
            "\n",
            "Video1.mp4              [  <=>               ]  51.07K   141KB/s    in 0.4s    \n",
            "\n",
            "2019-03-02 21:03:12 (141 KB/s) - ‘Video1.mp4’ saved [52294]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UYoh1l9A_wLT",
        "colab_type": "code",
        "outputId": "57323663-696a-4b59-ea6a-c5471bcfe723",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd ..\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "NcH27kbD_1UG",
        "colab_type": "code",
        "outputId": "ebd02064-71af-42c9-c8b8-99fd51719ed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#@title Setting parameters\n",
        "\n",
        "\n",
        "# images --> Input image / directory of images.\n",
        "# reso   --> Input image resolution\n",
        "# detect_image --> flag to decide to detect video or single photo\n",
        "\n",
        "images = os.getcwd() + '/Images'\n",
        "images_det = os.getcwd() + '/Images_Detection'\n",
        "print(images, images_det)\n",
        "batch_size = 1\n",
        "confidence = 0.5\n",
        "nms_thesh = 0.4\n",
        "reso = 416\n",
        "weights_file = \"yolov3.weights\"\n",
        "config_file = \"yolov3.cfg\"\n",
        "start = 0\n",
        "detect_image = True\n",
        "CUDA = torch.cuda.is_available()\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Images /content/Images_Detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k10Bjc62_4Vv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7429dbb7-32a4-4926-e517-b1ae9073e4af"
      },
      "cell_type": "code",
      "source": [
        "#@title Making directory for COCO names file\n",
        "!mkdir data\n",
        "os.chdir('./data')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZgiT7Tcl_7ip",
        "colab_type": "code",
        "outputId": "1b503714-08e2-4012-bb8a-e0313b5301de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "#@title COCO names file\n",
        "!wget https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-03-02 21:11:30--  https://raw.githubusercontent.com/ayooshkathuria/YOLO_v3_tutorial_from_scratch/master/data/coco.names\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 625 [text/plain]\n",
            "Saving to: ‘coco.names.1’\n",
            "\n",
            "\rcoco.names.1          0%[                    ]       0  --.-KB/s               \rcoco.names.1        100%[===================>]     625  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-02 21:11:31 (118 MB/s) - ‘coco.names.1’ saved [625/625]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8bo09lUj_-y-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_classes(namefile):\n",
        "  fp = open(namefile, 'r')\n",
        "  names = fp.read().split(\"\\n\")[:-1] #discard the last\n",
        "  return names\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jDKZhffeAC4w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# COCO dataset has 80 different classes\n",
        "num_classes = 80\n",
        "classes = load_classes(\"coco.names\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ucS9d3vVAFr5",
        "colab_type": "code",
        "outputId": "db3897a0-0f41-4961-c6cb-33e05e5b89d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd ..\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "twrYk8CzAH3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def write_video_box(x, results):\n",
        "  c1 = tuple(x[1:3].int())\n",
        "  c2 = tuple(x[3:5].int())\n",
        "  img = results\n",
        "  cls = int(x[-1])\n",
        "  color = random.choice(colors)\n",
        "  label = \"{0}\".format(classes[cls])\n",
        "  cv2.rectangle(img, c1, c2,color, 1)\n",
        "  t_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_PLAIN, 1 , 1)[0]\n",
        "  c2 = c1[0] + t_size[0] + 3, c1[1] + t_size[1] + 4\n",
        "  cv2.rectangle(img, c1, c2,color, -1)\n",
        "  cv2.putText(img, label, (c1[0], c1[1] + t_size[1] + 4), cv2.FONT_HERSHEY_PLAIN, 1, [225,255,255], 1);\n",
        "  return img\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DdtZDA1VAKTR",
        "colab_type": "code",
        "outputId": "c8dbf1f4-f738-4b75-c1c5-16a1ac7fb67a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        }
      },
      "cell_type": "code",
      "source": [
        "# Set up the network\n",
        "print(\"Loading network...\")\n",
        "model = Darknet(config_file)\n",
        "model.load_weights(weights_file)\n",
        "print(\"Network successfully loaded\")\n",
        "\n",
        "\n",
        "model.net_info[\"height\"] = reso\n",
        "inp_dim = int(model.net_info[\"height\"])\n",
        "assert inp_dim % 32 == 0\n",
        "assert inp_dim > 32\n",
        "\n",
        "# if GPU is available allocate the model\n",
        "if CUDA:\n",
        "  model.cuda()\n",
        "  \n",
        "# Set the model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "if detect_image:\n",
        "  read_dir = time.time()\n",
        "  #Detection phase\n",
        "  try:\n",
        "      imlist = [osp.join(osp.realpath('.'), images, img) for img in os.listdir(images)]\n",
        "  except NotADirectoryError:\n",
        "      imlist = []\n",
        "      imlist.append(osp.join(osp.realpath('.'), images))\n",
        "  except FileNotFoundError:\n",
        "      print (\"No file or directory with the name {}\".format(images))\n",
        "      exit()\n",
        "\n",
        "  if not os.path.exists(images_det):\n",
        "      os.makedirs(images_det)\n",
        "\n",
        "  load_batch = time.time()\n",
        "  loaded_ims = [cv2.imread(x) for x in imlist]\n",
        "\n",
        "  im_batches = list(map(prep_image, loaded_ims, [inp_dim for x in range(len(imlist))]))\n",
        "  im_dim_list = [(x.shape[1], x.shape[0]) for x in loaded_ims]\n",
        "  im_dim_list = torch.FloatTensor(im_dim_list).repeat(1,2)\n",
        "\n",
        "\n",
        "  leftover = 0\n",
        "  if (len(im_dim_list) % batch_size):\n",
        "      leftover = 1\n",
        "\n",
        "  if batch_size != 1:\n",
        "      num_batches = len(imlist) // batch_size + leftover            \n",
        "      im_batches = [torch.cat((im_batches[i*batch_size : min((i +  1)*batch_size,\n",
        "                          len(im_batches))]))  for i in range(num_batches)]  \n",
        "\n",
        "  write = 0\n",
        "\n",
        "\n",
        "  if CUDA:\n",
        "      im_dim_list = im_dim_list.cuda()\n",
        "\n",
        "  start_det_loop = time.time()\n",
        "  for i, batch in enumerate(im_batches):\n",
        "  #load the image \n",
        "      start = time.time()\n",
        "      if CUDA:\n",
        "          batch = batch.cuda()\n",
        "      with torch.no_grad():\n",
        "          prediction = model(Variable(batch), CUDA)\n",
        "\n",
        "      prediction = write_results(prediction, confidence, num_classes, nms_conf = nms_thesh)\n",
        "\n",
        "      end = time.time()\n",
        "\n",
        "      if type(prediction) == int:\n",
        "\n",
        "          for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "              im_id = i*batch_size + im_num\n",
        "              print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "              print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \"\"))\n",
        "              print(\"----------------------------------------------------------\")\n",
        "          continue\n",
        "\n",
        "      prediction[:,0] += i*batch_size    #transform the atribute from index in batch to index in imlist \n",
        "\n",
        "      if not write:                      #If we have't initialised output\n",
        "          output = prediction  \n",
        "          write = 1\n",
        "      else:\n",
        "          output = torch.cat((output,prediction))\n",
        "\n",
        "      for im_num, image in enumerate(imlist[i*batch_size: min((i +  1)*batch_size, len(imlist))]):\n",
        "          im_id = i*batch_size + im_num\n",
        "          objs = [classes[int(x[-1])] for x in output if int(x[0]) == im_id]\n",
        "          print(\"{0:20s} predicted in {1:6.3f} seconds\".format(image.split(\"/\")[-1], (end - start)/batch_size))\n",
        "          print(\"{0:20s} {1:s}\".format(\"Objects Detected:\", \" \".join(objs)))\n",
        "          print(\"----------------------------------------------------------\")\n",
        "\n",
        "      if CUDA:\n",
        "          torch.cuda.synchronize()       \n",
        "  try:\n",
        "      output\n",
        "  except NameError:\n",
        "      print (\"No detections were made\")\n",
        "      exit()\n",
        "\n",
        "  im_dim_list = torch.index_select(im_dim_list, 0, output[:,0].long())\n",
        "\n",
        "  scaling_factor = torch.min(416/im_dim_list,1)[0].view(-1,1)\n",
        "\n",
        "\n",
        "  output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim_list[:,0].view(-1,1))/2\n",
        "  output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim_list[:,1].view(-1,1))/2\n",
        "\n",
        "\n",
        "\n",
        "  output[:,1:5] /= scaling_factor\n",
        "\n",
        "  for i in range(output.shape[0]):\n",
        "      output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim_list[i,0])\n",
        "      output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim_list[i,1])\n",
        "\n",
        "\n",
        "  output_recast = time.time()\n",
        "  class_load = time.time()\n",
        "  colors = pkl.load(open(\"pallete\", \"rb\"))\n",
        "\n",
        "  draw = time.time()\n",
        "  \n",
        "  list(map(lambda x: write_box(x, loaded_ims), output))\n",
        "\n",
        "  det_names = pd.Series(imlist).apply(lambda x: \"{}/det_{}\".format(images_det,x.split(\"/\")[-1]))\n",
        "\n",
        "  list(map(cv2.imwrite, det_names, loaded_ims))\n",
        "\n",
        "\n",
        "  end = time.time()\n",
        "\n",
        "  print(\"SUMMARY\")\n",
        "  print(\"----------------------------------------------------------\")\n",
        "  print(\"{:25s}: {}\".format(\"Task\", \"Time Taken (in seconds)\"))\n",
        "  print()\n",
        "  print(\"{:25s}: {:2.3f}\".format(\"Reading addresses\", load_batch - read_dir))\n",
        "  print(\"{:25s}: {:2.3f}\".format(\"Loading batch\", start_det_loop - load_batch))\n",
        "  print(\"{:25s}: {:2.3f}\".format(\"Detection (\" + str(len(imlist)) +  \" images)\", output_recast - start_det_loop))\n",
        "  print(\"{:25s}: {:2.3f}\".format(\"Output Processing\", class_load - output_recast))\n",
        "  print(\"{:25s}: {:2.3f}\".format(\"Drawing Boxes\", end - draw))\n",
        "  print(\"{:25s}: {:2.3f}\".format(\"Average time_per_img\", (end - load_batch)/len(imlist)))\n",
        "  print(\"----------------------------------------------------------\")\n",
        "\n",
        "\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "else:\n",
        "  #Detection phase\n",
        "  #Use cv2.VideoCapture('your video file name or path')\n",
        "  cap = cv2.VideoCapture('Video1.mp4') #cap = cv.VideoCapture(0)\n",
        "  \n",
        "  fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "  sz = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)),\n",
        "       int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
        "  vout = cv2.VideoWriter()\n",
        "  vout.open('./video_output.avi',fourcc,fps,sz,True)\n",
        "\n",
        "  \n",
        "  assert cap.isOpened(), 'Cannot capture source'\n",
        "\n",
        "  frames = 0 \n",
        "  start = time.time()\n",
        "\n",
        "  while cap.isOpened():\n",
        "      ret, frame = cap.read()\n",
        "\n",
        "      if ret:   \n",
        "          img = prep_image(frame, inp_dim)\n",
        "          im_dim = frame.shape[1], frame.shape[0]\n",
        "          im_dim = torch.FloatTensor(im_dim).repeat(1,2)   \n",
        "\n",
        "          if CUDA:\n",
        "              im_dim = im_dim.cuda()\n",
        "              img = img.cuda()\n",
        "\n",
        "          with torch.no_grad():\n",
        "              output = model(Variable(img, volatile = True), CUDA)\n",
        "          output = write_results(output, confidence, num_classes, nms_conf = nms_thesh)\n",
        "\n",
        "\n",
        "          if type(output) == int:\n",
        "              frames += 1\n",
        "              key = cv2.waitKey(1)\n",
        "              if key & 0xFF == ord('q'):\n",
        "                  break\n",
        "              continue\n",
        "\n",
        "          im_dim = im_dim.repeat(output.size(0), 1)\n",
        "          scaling_factor = torch.min(416/im_dim,1)[0].view(-1,1)\n",
        "\n",
        "          output[:,[1,3]] -= (inp_dim - scaling_factor*im_dim[:,0].view(-1,1))/2\n",
        "          output[:,[2,4]] -= (inp_dim - scaling_factor*im_dim[:,1].view(-1,1))/2\n",
        "\n",
        "          output[:,1:5] /= scaling_factor\n",
        "\n",
        "          for i in range(output.shape[0]):\n",
        "              output[i, [1,3]] = torch.clamp(output[i, [1,3]], 0.0, im_dim[i,0])\n",
        "              output[i, [2,4]] = torch.clamp(output[i, [2,4]], 0.0, im_dim[i,1])\n",
        "\n",
        "\n",
        "          classes = load_classes('data/coco.names')\n",
        "          colors = pkl.load(open(\"pallete\", \"rb\"))\n",
        "\n",
        "          list(map(lambda x: write_video_box(x, frame), output))\n",
        "          \n",
        "          vout.write(frame)\n",
        "          \n",
        "          key = cv2.waitKey(1)\n",
        "          if key & 0xFF == ord('q'):\n",
        "              FPS = frames // (time.time() - start)\n",
        "              break\n",
        "          frames += 1\n",
        "          \n",
        "      else:\n",
        "          FPS = frames // (time.time() - start)\n",
        "          break\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading network...\n",
            "Network successfully loaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-40f1ef052510>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m   \u001b[0mloaded_ims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimlist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m   \u001b[0mim_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaded_ims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0minp_dim\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m   \u001b[0mim_dim_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_ims\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m   \u001b[0mim_dim_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim_dim_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mprep_image\u001b[0;34m(img, inp_dim)\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m     \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mletterbox_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/util.py\u001b[0m in \u001b[0;36mletterbox_image\u001b[0;34m(img, inp_dim)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mletterbox_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;34m'''resize image with unchanged aspect ratio using padding'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp_dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mnew_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_w\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimg_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mimg_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "d63sj0_7AS7m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}